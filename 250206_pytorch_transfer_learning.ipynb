{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# ─── 커스텀 Dataset 클래스 ─────────────────────────────\n",
    "class ApparelDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        csv_file: CSV 파일 경로 (train.csv, val.csv 등)\n",
    "        root_dir: 이미지가 저장된 루트 디렉토리\n",
    "                  예: \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\clothes_dataset\"\n",
    "        transform: 이미지 변환 함수\n",
    "        \n",
    "        CSV 파일 포맷:\n",
    "          - 첫 번째 열: 인덱스 (사용하지 않음)\n",
    "          - 두 번째 열: 이미지 파일명 (예: \"./clothes_dataset/red_dress/xxx.jpg\" 또는 \".\\\\clothes_dataset\\\\red_dress\\\\xxx.jpg\")\n",
    "          - 세 번째 열부터: 11개의 라벨 (0 또는 1)\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # CSV의 두 번째 열에서 이미지 파일명을 읽습니다.\n",
    "        img_filename = str(self.data.iloc[idx, 1]).strip()\n",
    "        # 백슬래시를 슬래시로 변경하여 경로 형식을 통일합니다.\n",
    "        img_filename = img_filename.replace(\"\\\\\", \"/\")\n",
    "        # 만약 파일명이 \"./clothes_dataset/\"로 시작하면 해당 접두어를 제거합니다.\n",
    "        prefix = \"./clothes_dataset/\"\n",
    "        if img_filename.startswith(prefix):\n",
    "            img_filename = img_filename[len(prefix):]\n",
    "        # 최종 경로: root_dir과 img_filename을 결합\n",
    "        img_path = os.path.join(self.root_dir, img_filename)\n",
    "        \n",
    "        # 이미지 열기 (RGB 모드로 변환)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        # 세 번째 열부터 11개의 라벨을 float32 배열로 변환\n",
    "        labels = self.data.iloc[idx, 2:].values.astype('float32')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __init__ 메서드:\n",
    "  - CSV 파일을 읽어서 self.data에 저장합니다.\n",
    "  - root_dir는 이미지 파일들이 저장된 최상위 폴더 경로입니다.\n",
    "  - transform은 이미지 전처리(예: 리사이즈, 정규화) 함수입니다.\n",
    "\n",
    "- __len__ 메서드:\n",
    "  - 데이터셋의 길이(샘플 개수)를 반환합니다.\n",
    "\n",
    "- __getitem__ 메서드:\n",
    "  - 지정한 인덱스의 이미지 파일명을 CSV에서 가져와 문자열로 변환합니다.\n",
    "  - 경로의 백슬래시를 슬래시로 변환하고, 접두어(\"./clothes_dataset/\")가 있다면 제거합니다.\n",
    "  - 최종 경로를 os.path.join을 통해 생성한 후, 이미지를 열어 RGB로 변환합니다.\n",
    "  - 이후 CSV의 나머지 열에서 11개 라벨을 읽어 텐서로 변환하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 경로 및 CSV 파일 설정 ─────────────────────────────\n",
    "data_dir = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\clothes_dataset\"\n",
    "train_csv = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\train.csv\"\n",
    "val_csv = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\val.csv\"\n",
    "test_csv = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 데이터 전처리 ─────────────────────────────\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resize: 모든 이미지를 224x224 픽셀 크기로 맞춥니다.\n",
    "- ToTensor: 이미지를 파이토치 텐서로 변환합니다.\n",
    "- Normalize: 사전 학습된 모델(ImageNet 기준)에 맞게 정규화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Dataset 및 DataLoader 생성 ─────────────────────────────\n",
    "train_data = ApparelDataset(csv_file=train_csv, root_dir=data_dir, transform=transform)\n",
    "val_data = ApparelDataset(csv_file=val_csv, root_dir=data_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ApparelDataset 객체를 생성하여 훈련 데이터와 검증 데이터를 만듭니다.\n",
    "- DataLoader는 데이터를 배치 단위로 로드하며, 훈련 시 셔플(shuffle)을 활성화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ─── 사전 학습된 ResNet-18 모델 불러오기 및 전이학습 적용 ─────────────────────────────\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전이학습: 모든 파라미터 동결 (freeze)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 fc 레이어 수정: 출력 클래스 수를 11로 변경\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 11)\n",
    "\n",
    "# 마지막 fc 레이어의 파라미터만 학습하도록 설정\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 파라미터 동결:\n",
    "  - 모델의 모든 파라미터에 대해 requires_grad를 False로 설정하여 기존 사전 학습된 가중치가 업데이트되지 않도록 합니다.\n",
    "\n",
    "- 마지막 fc 레이어 수정:\n",
    "  - 기존 모델의 마지막 fully connected 레이어를 새로운 데이터셋의 클래스 수(11)로 맞추기 위해 재정의합니다.\n",
    "\n",
    "- fc 레이어 파라미터 학습 활성화:\n",
    "  - 새로 정의한 fc 레이어의 파라미터에 대해서만 requires_grad를 True로 설정하여 학습이 진행되도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 모델을 GPU로 이동 ─────────────────────────────\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 손실 함수 및 옵티마이저 설정 ─────────────────────────────\n",
    "# BCEWithLogitsLoss는 내부에서 sigmoid를 적용한 후 이진 교차 엔트로피 손실을 계산함.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ─── 모델 훈련 함수 ─────────────────────────────\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # 훈련 루프: 각 배치에 대해 손실을 계산하고, 역전파 수행\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # 모델의 raw logits 출력\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # 평가 루프: 검증 데이터셋에 대해 모델 평가\n",
    "        model.eval()\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                # 평가 시, sigmoid를 적용하여 확률로 변환 후, 0.5 임계값을 기준으로 예측\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                correct_preds += (preds == labels).sum().item()\n",
    "                total_preds += labels.size(0) * labels.size(1)\n",
    "\n",
    "        epoch_acc = correct_preds / total_preds\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 손실 함수:\n",
    "  - BCEWithLogitsLoss는 마지막 레이어의 raw logits(활성화 함수 없이 출력된 값)에 대해 내부에서 sigmoid를 적용하여 이진 교차 엔트로피 손실을 계산합니다.\n",
    "\n",
    "- 옵티마이저:\n",
    "  - Adam 옵티마이저를 사용하여 모델 파라미터를 업데이트합니다.\n",
    "\n",
    "- 훈련 루프:\n",
    "  - 각 에포크마다 훈련 데이터에 대해 모델을 학습시키며, 배치별 손실을 누적하여 에포크 손실을 계산합니다.\n",
    "\n",
    "- 평가 루프:\n",
    "  - 검증 데이터를 사용하여 모델을 평가합니다.\n",
    "  - 평가 시에는 raw logits에 대해 torch.sigmoid를 적용하고, 0.5 임계값을 사용하여 각 클래스의 예측(0 또는 1)을 결정합니다.\n",
    "\n",
    "- 에포크별 출력:\n",
    "  - 에포크마다 평균 손실과 정확도를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.2600, Accuracy: 0.9491\n",
      "Epoch 2/10, Loss: 0.1415, Accuracy: 0.9638\n",
      "Epoch 3/10, Loss: 0.1132, Accuracy: 0.9697\n",
      "Epoch 4/10, Loss: 0.0992, Accuracy: 0.9712\n",
      "Epoch 5/10, Loss: 0.0921, Accuracy: 0.9733\n",
      "Epoch 6/10, Loss: 0.0865, Accuracy: 0.9743\n",
      "Epoch 7/10, Loss: 0.0826, Accuracy: 0.9735\n",
      "Epoch 8/10, Loss: 0.0800, Accuracy: 0.9748\n",
      "Epoch 9/10, Loss: 0.0760, Accuracy: 0.9761\n",
      "Epoch 10/10, Loss: 0.0736, Accuracy: 0.9759\n"
     ]
    }
   ],
   "source": [
    "# ─── 모델 훈련 시작 ─────────────────────────────\n",
    "trained_model = train_model(model, train_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 훈련된 모델 저장 ─────────────────────────────\n",
    "torch.save(trained_model.state_dict(), 'apparel_resnet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for black:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.95      2413\n",
      "         1.0       0.93      0.84      0.88      1003\n",
      "\n",
      "    accuracy                           0.93      3416\n",
      "   macro avg       0.93      0.91      0.92      3416\n",
      "weighted avg       0.93      0.93      0.93      3416\n",
      "\n",
      "Classification Report for blue:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.98      0.97      2578\n",
      "         1.0       0.94      0.84      0.89       838\n",
      "\n",
      "    accuracy                           0.95      3416\n",
      "   macro avg       0.95      0.91      0.93      3416\n",
      "weighted avg       0.95      0.95      0.95      3416\n",
      "\n",
      "Classification Report for brown:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3170\n",
      "         1.0       0.91      0.82      0.86       246\n",
      "\n",
      "    accuracy                           0.98      3416\n",
      "   macro avg       0.95      0.91      0.93      3416\n",
      "weighted avg       0.98      0.98      0.98      3416\n",
      "\n",
      "Classification Report for green:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      3106\n",
      "         1.0       0.93      0.90      0.92       310\n",
      "\n",
      "    accuracy                           0.99      3416\n",
      "   macro avg       0.96      0.95      0.95      3416\n",
      "weighted avg       0.98      0.99      0.98      3416\n",
      "\n",
      "Classification Report for red:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      2933\n",
      "         1.0       0.96      0.96      0.96       483\n",
      "\n",
      "    accuracy                           0.99      3416\n",
      "   macro avg       0.98      0.98      0.98      3416\n",
      "weighted avg       0.99      0.99      0.99      3416\n",
      "\n",
      "Classification Report for white:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      2880\n",
      "         1.0       0.94      0.92      0.93       536\n",
      "\n",
      "    accuracy                           0.98      3416\n",
      "   macro avg       0.96      0.95      0.96      3416\n",
      "weighted avg       0.98      0.98      0.98      3416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 테스트 데이터셋 로드 (이미 ApparelDataset 클래스와 transform, data_dir, test_csv가 설정되어 있다고 가정)\n",
    "test_data = ApparelDataset(csv_file=test_csv, root_dir=data_dir, transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)  # raw logits 출력\n",
    "        # BCEWithLogitsLoss를 사용할 때는 평가 시 sigmoid를 적용하여 0.5 기준으로 이진 예측\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# 배치별 예측 결과와 정답을 하나의 배열로 결합\n",
    "all_preds = np.concatenate(all_preds, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# 색상에 해당하는 출력은 첫 6개 열입니다.\n",
    "color_preds = all_preds[:, :6]\n",
    "color_labels = all_labels[:, :6]\n",
    "\n",
    "# 각 색상별 성능 평가\n",
    "colors = ['black', 'blue', 'brown', 'green', 'red', 'white']\n",
    "\n",
    "for i, color in enumerate(colors):\n",
    "    print(f\"Classification Report for {color}:\")\n",
    "    # classification_report는 기본적으로 0과 1의 값에 대해 정밀도, 재현율, F1 점수를 계산합니다.\n",
    "    report = classification_report(color_labels[:, i], color_preds[:, i], zero_division=0)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Colors: ['brown']\n",
      "Predicted Items: ['pants']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# ----- 설정 -----\n",
    "# 예측할 샘플 이미지 파일 경로 (절대 경로로 수정)\n",
    "sample_image_path = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\clothes_dataset\\\\brown_pants\\\\2b4a9eb1174f5a0bcd0ccd2668c5e23d7252e72f.jpg\"\n",
    "\n",
    "# 저장된 모델 파일 경로\n",
    "model_path = \"apparel_resnet_model.pth\"\n",
    "\n",
    "# 클래스 이름 (출력 순서에 맞게)\n",
    "colors = ['black', 'blue', 'brown', 'green', 'red', 'white']\n",
    "items = ['dress', 'shirt', 'pants', 'shorts', 'shoes']\n",
    "\n",
    "# ----- 전처리 (학습 시 사용한 transform과 동일) -----\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 모델 입력 크기\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ----- 이미지 로드 및 전처리 -----\n",
    "# 이미지 열기 및 RGB 변환\n",
    "image = Image.open(sample_image_path).convert(\"RGB\")\n",
    "# 전처리 적용\n",
    "input_tensor = transform(image)\n",
    "# 모델은 배치 입력을 기대하므로 배치 차원 추가 (shape: [1, 3, 224, 224])\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "# ----- 모델 로드 -----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ResNet-18 모델 구조 생성 (학습할 때와 동일하게 구성)\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 11)  # 출력 클래스 11개 (6: 색상, 5: 품목)\n",
    "\n",
    "# 저장된 가중치 로드 (map_location을 통해 CPU/GPU에 맞게 로드)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()  # 평가 모드 전환\n",
    "\n",
    "# ----- 추론 수행 -----\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor.to(device))  # raw logits 출력\n",
    "    # BCEWithLogitsLoss 사용 시 내부 sigmoid 적용 → 여기서는 평가 시 sigmoid를 명시적으로 적용\n",
    "    probabilities = torch.sigmoid(outputs)\n",
    "    # 0.5 임계값 기준으로 이진 예측 (0 또는 1)\n",
    "    prediction = (probabilities > 0.5).float()\n",
    "\n",
    "# ----- 결과 해석 -----\n",
    "pred = prediction.cpu().numpy()[0]  # 예측 결과 배열 (크기 11)\n",
    "color_pred = pred[:6]  # 첫 6개: 색상 예측 결과\n",
    "item_pred = pred[6:]   # 다음 5개: 품목 예측 결과\n",
    "\n",
    "predicted_colors = [colors[i] for i, val in enumerate(color_pred) if val == 1.0]\n",
    "predicted_items = [items[i] for i, val in enumerate(item_pred) if val == 1.0]\n",
    "\n",
    "print(\"Predicted Colors:\", predicted_colors)\n",
    "print(\"Predicted Items:\", predicted_items)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
