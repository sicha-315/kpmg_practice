{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# ─── 커스텀 Dataset 클래스 ─────────────────────────────\n",
    "class ApparelDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        csv_file: CSV 파일 경로 (train.csv, val.csv 등)\n",
    "        root_dir: 이미지가 저장된 루트 디렉토리\n",
    "                  예: \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\clothes_dataset\"\n",
    "        transform: 이미지 변환 함수\n",
    "        \n",
    "        CSV 파일 포맷:\n",
    "          - 첫 번째 열: 인덱스 (사용하지 않음)\n",
    "          - 두 번째 열: 이미지 파일명 (예: \"./clothes_dataset/red_dress/xxx.jpg\" 또는 \".\\\\clothes_dataset\\\\red_dress\\\\xxx.jpg\")\n",
    "          - 세 번째 열부터: 11개의 라벨 (0 또는 1)\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # CSV의 두 번째 열에서 이미지 파일명을 읽습니다.\n",
    "        img_filename = str(self.data.iloc[idx, 1]).strip()\n",
    "        # 백슬래시를 슬래시로 변경하여 경로 형식을 통일합니다.\n",
    "        img_filename = img_filename.replace(\"\\\\\", \"/\")\n",
    "        # 만약 파일명이 \"./clothes_dataset/\"로 시작하면 해당 접두어를 제거합니다.\n",
    "        prefix = \"./clothes_dataset/\"\n",
    "        if img_filename.startswith(prefix):\n",
    "            img_filename = img_filename[len(prefix):]\n",
    "        # 최종 경로: root_dir과 img_filename을 결합\n",
    "        img_path = os.path.join(self.root_dir, img_filename)\n",
    "        \n",
    "        # 이미지 열기 (RGB 모드로 변환)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        # 세 번째 열부터 11개의 라벨을 float32 배열로 변환\n",
    "        labels = self.data.iloc[idx, 2:].values.astype('float32')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __init__ 메서드:\n",
    "  - CSV 파일을 읽어서 self.data에 저장합니다.\n",
    "  - root_dir는 이미지 파일들이 저장된 최상위 폴더 경로입니다.\n",
    "  - transform은 이미지 전처리(예: 리사이즈, 정규화) 함수입니다.\n",
    "\n",
    "- __len__ 메서드:\n",
    "  - 데이터셋의 길이(샘플 개수)를 반환합니다.\n",
    "\n",
    "- __getitem__ 메서드:\n",
    "  - 지정한 인덱스의 이미지 파일명을 CSV에서 가져와 문자열로 변환합니다.\n",
    "  - 경로의 백슬래시를 슬래시로 변환하고, 접두어(\"./clothes_dataset/\")가 있다면 제거합니다.\n",
    "  - 최종 경로를 os.path.join을 통해 생성한 후, 이미지를 열어 RGB로 변환합니다.\n",
    "  - 이후 CSV의 나머지 열에서 11개 라벨을 읽어 텐서로 변환하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 경로 및 CSV 파일 설정 ─────────────────────────────\n",
    "data_dir = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\clothes_dataset\"\n",
    "train_csv = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\train.csv\"\n",
    "val_csv = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\val.csv\"\n",
    "test_csv = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\data\\\\apparel-image-dataset-2\\\\test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 데이터 전처리 ─────────────────────────────\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resize: 모든 이미지를 224x224 픽셀 크기로 맞춥니다.\n",
    "- ToTensor: 이미지를 파이토치 텐서로 변환합니다.\n",
    "- Normalize: 사전 학습된 모델(ImageNet 기준)에 맞게 정규화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Dataset 및 DataLoader 생성 ─────────────────────────────\n",
    "train_data = ApparelDataset(csv_file=train_csv, root_dir=data_dir, transform=transform)\n",
    "val_data = ApparelDataset(csv_file=val_csv, root_dir=data_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ApparelDataset 객체를 생성하여 훈련 데이터와 검증 데이터를 만듭니다.\n",
    "- DataLoader는 데이터를 배치 단위로 로드하며, 훈련 시 셔플(shuffle)을 활성화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\myGPU\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\myGPU\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ─── 사전 학습된 ResNet-18 모델 불러오기 및 전이학습 적용 ─────────────────────────────\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전이학습: 모든 파라미터 동결 (freeze)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 fc 레이어 수정: 출력 클래스 수를 11로 변경\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 11)\n",
    "\n",
    "# 마지막 fc 레이어의 파라미터만 학습하도록 설정\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 파라미터 동결:\n",
    "  - 모델의 모든 파라미터에 대해 requires_grad를 False로 설정하여 기존 사전 학습된 가중치가 업데이트되지 않도록 합니다.\n",
    "\n",
    "- 마지막 fc 레이어 수정:\n",
    "  - 기존 모델의 마지막 fully connected 레이어를 새로운 데이터셋의 클래스 수(11)로 맞추기 위해 재정의합니다.\n",
    "\n",
    "- fc 레이어 파라미터 학습 활성화:\n",
    "  - 새로 정의한 fc 레이어의 파라미터에 대해서만 requires_grad를 True로 설정하여 학습이 진행되도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 모델을 GPU로 이동 ─────────────────────────────\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 손실 함수 및 옵티마이저 설정 ─────────────────────────────\n",
    "# BCEWithLogitsLoss는 내부에서 sigmoid를 적용한 후 이진 교차 엔트로피 손실을 계산함.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ─── 모델 훈련 함수 ─────────────────────────────\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # 훈련 루프: 각 배치에 대해 손실을 계산하고, 역전파 수행\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # 모델의 raw logits 출력\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # 평가 루프: 검증 데이터셋에 대해 모델 평가\n",
    "        model.eval()\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                # 평가 시, sigmoid를 적용하여 확률로 변환 후, 0.5 임계값을 기준으로 예측\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                correct_preds += (preds == labels).sum().item()\n",
    "                total_preds += labels.size(0) * labels.size(1)\n",
    "\n",
    "        epoch_acc = correct_preds / total_preds\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 손실 함수:\n",
    "  - BCEWithLogitsLoss는 마지막 레이어의 raw logits(활성화 함수 없이 출력된 값)에 대해 내부에서 sigmoid를 적용하여 이진 교차 엔트로피 손실을 계산합니다.\n",
    "\n",
    "- 옵티마이저:\n",
    "  - Adam 옵티마이저를 사용하여 모델 파라미터를 업데이트합니다.\n",
    "\n",
    "- 훈련 루프:\n",
    "  - 각 에포크마다 훈련 데이터에 대해 모델을 학습시키며, 배치별 손실을 누적하여 에포크 손실을 계산합니다.\n",
    "\n",
    "- 평가 루프:\n",
    "  - 검증 데이터를 사용하여 모델을 평가합니다.\n",
    "  - 평가 시에는 raw logits에 대해 torch.sigmoid를 적용하고, 0.5 임계값을 사용하여 각 클래스의 예측(0 또는 1)을 결정합니다.\n",
    "\n",
    "- 에포크별 출력:\n",
    "  - 에포크마다 평균 손실과 정확도를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0739, Accuracy: 0.9749\n",
      "Epoch 2/10, Loss: 0.0695, Accuracy: 0.9760\n",
      "Epoch 3/10, Loss: 0.0681, Accuracy: 0.9775\n",
      "Epoch 4/10, Loss: 0.0660, Accuracy: 0.9775\n",
      "Epoch 5/10, Loss: 0.0669, Accuracy: 0.9770\n",
      "Epoch 6/10, Loss: 0.0649, Accuracy: 0.9769\n",
      "Epoch 7/10, Loss: 0.0635, Accuracy: 0.9771\n",
      "Epoch 8/10, Loss: 0.0638, Accuracy: 0.9759\n",
      "Epoch 9/10, Loss: 0.0620, Accuracy: 0.9771\n",
      "Epoch 10/10, Loss: 0.0620, Accuracy: 0.9775\n"
     ]
    }
   ],
   "source": [
    "# ─── 모델 훈련 시작 ─────────────────────────────\n",
    "trained_model = train_model(model, train_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 훈련된 모델 저장 ─────────────────────────────\n",
    "torch.save(trained_model.state_dict(), 'apparel_resnet_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
